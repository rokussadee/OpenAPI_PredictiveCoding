{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# metacognitive prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import queue\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getenv(\"SYS_PATH\"))\n",
    "print(f'{os.getenv(\"SYS_PATH\")}')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, OpenAIError\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "from bson.objectid import ObjectId\n",
    "from typing import Optional\n",
    "import threading\n",
    "\n",
    "from models.user import create_user\n",
    "from models.chat_message import create_chat_message, ChatMessageData\n",
    "from models.conversation import create_conversation\n",
    "from models.chatbot_response import create_chatbot_response\n",
    "from models.expectation import create_expectation\n",
    "from models.expectation_revision import create_expectation_revision\n",
    "from models.violation import create_violation\n",
    "\n",
    "from utils.model_operations import create_model, get_model, get_chat_history\n",
    "from services.mock_service import mock_user_data, mock_expectation_data, mock_expectation_revision_data, mock_message_data, mock_violation_data, mock_chatbot_response_data\n",
    "from utils.helpers import CustomOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../services/mongo_service.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.mongo_service import mongo_client, ping_client\n",
    "db_client = mongo_client()\n",
    "ping_client(db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"\"\n",
    "chat_output = CustomOutput()\n",
    "user_input_queue = queue.Queue()\n",
    "\n",
    "set_user = None\n",
    "set_conversation = None\n",
    "chat_history = []\n",
    "\n",
    "button_click_event = threading.Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = create_user(email=mock_user_data[\"email\"], password=mock_user_data[\"password\"])\n",
    "print(f\"test_user: {test_user}\\nis of type{type(test_user)}\")\n",
    "saved_user_id = create_model(collection_name=\"users\", model_data=test_user, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conversation = create_conversation(user_id=saved_user_id)\n",
    "saved_conversation_id = create_model(collection_name=\"conversations\", model_data=test_conversation, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_expectation = create_expectation(reasoning=mock_expectation_data[\"reasoning\"], user_predictions=mock_expectation_data[\"user_predictions\"], additional_data=mock_expectation_data[\"additional_data\"])\n",
    "saved_expectation_id = create_model(collection_name=\"expectations\", model_data=test_expectation, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_expectation_revision = create_expectation_revision(revised_input_possibilities=mock_expectation_revision_data[\"revised_input_possibilities\"], prediction_error=-0.045, initial_expectation_id=saved_expectation_id)\n",
    "saved_expectation_revision_id = create_model(collection_name=\"expectation_revisions\", model_data=test_expectation_revision, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_message = create_chat_message(user_id=saved_user_id, content=mock_message_data[\"content\"], conversation_id=saved_conversation_id)\n",
    "saved_message_id = create_model(collection_name=\"chat_messages\", model_data=test_message, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_violation = create_violation(last_llm_response_id=None, expectation_id=saved_expectation_id, voe_thought=mock_violation_data[\"voe_thought\"])\n",
    "saved_violation_id = create_model(collection_name=\"violations\", model_data=test_violation, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model(collection_name=\"users\", model_id=saved_user_id, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mock_expectation_data[\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(\n",
    "    api_key=apikey\n",
    ")\n",
    "print(openai_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chatbot(message) -> str:\n",
    "    try:\n",
    "        chat_completion_stream = openai_client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\":\"user\",\n",
    "                    \"content\":message,\n",
    "                 },\n",
    "            ],\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            stream=True\n",
    "        )\n",
    "        print(chat_completion_stream)\n",
    "        message = \"\"\n",
    "        chat_output.append_stdout(f\"first 'message' value in stream_chatbot: {message}\", debug=True)\n",
    "        chat_output.append_stdout(f\"Chatbot: \", stream=True)\n",
    "        for chunk in chat_completion_stream:\n",
    "            if chunk.choices[0].delta.content is not None:\n",
    "                chat_output.append_stdout(f\"{chunk.choices[0].delta.content}\", stream=True)\n",
    "                message += chunk.choices[0].delta.content\n",
    "        chat_output.append_stdout(f\"\\n\")\n",
    "        \n",
    "        chat_output.append_stdout(f\"final 'message' value in stream_chatbot: {message}\", debug=True)\n",
    "        \n",
    "        return message\n",
    "    except OpenAIError as e:\n",
    "        #Handle API error here, e.g. retry or log\n",
    "        print(f\"OpenAI API returned an API Error: {e}\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(user_message) -> str:\n",
    "    message = stream_chatbot(user_message)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_user_message(user_message):\n",
    "    chat_output.append_stdout(f\"You: {user_message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_user_message(user_message):\n",
    "    chatbot(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_button_click():\n",
    "    chat_output.append_stdout(f\"handle button clicked\", debug=True)\n",
    "    chat_output.append_stdout(f\"text_input.value: {text_input.value}\", debug=True)\n",
    "    user_input_queue.put(text_input.value)\n",
    "    text_input.value=''\n",
    "    chat_output.append_stdout(f\"handle button clicked after setting queue value\", debug=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chat(user_id: ObjectId, conversation_id: Optional[ObjectId] = None):\n",
    "    global set_user, set_conversation, chat_history\n",
    "    set_user = get_model(collection_name=\"users\", model_id=saved_user_id, client=db_client)\n",
    "    if not conversation_id:\n",
    "        new_conversation = create_conversation(user_id=user_id)\n",
    "        conversation_id = create_model(collection_name=\"conversations\", model_data=new_conversation, client=db_client)\n",
    "    set_conversation = get_model(collection_name=\"conversations\", model_id=conversation_id, client=db_client)\n",
    "    \n",
    "    chat_history = get_chat_history(conversation_id=conversation_id, client=db_client)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_chat_history():\n",
    "    for item in chat_history:\n",
    "        if item.get('user_id'):\n",
    "            print_user_message(item.get('content'))\n",
    "        else:\n",
    "            chat_output.append_stdout(f\"Chatbot: \", stream=True)\n",
    "            chat_output.append_stdout(item.get('content'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prediction_task() -> dict:\n",
    "    # invoke reasoning process with Engagement Monitor Service\n",
    "    reasoning = mock_expectation_data[\"reasoning\"]\n",
    "    \n",
    "    # invoke user predictions with LLM Service\n",
    "    user_predictions = mock_expectation_data[\"user_predictions\"]\n",
    "    \n",
    "    # invoke vector db fact fetching with Knowledge Assessment Service\n",
    "    additional_data = mock_expectation_data[\"additional_data\"]\n",
    "    \n",
    "    # create and save Expectation\n",
    "    new_expectation = create_expectation(reasoning=reasoning, user_predictions=user_predictions, additional_data=additional_data)\n",
    "    expectation_id = create_model(collection_name=\"expectations\", model_data=new_expectation, client=db_client)\n",
    "    \n",
    "    # invoke prediction improvement with LLM Service\n",
    "    improved_predictions = mock_expectation_revision_data[\"revised_input_possibilities\"]\n",
    "    \n",
    "    # invoke prediction error calculation with ??? Service\n",
    "    prediction_error = 0.0\n",
    "    \n",
    "    # create and save ExpectationRevision\n",
    "    new_expectation_revision = create_expectation_revision(revised_input_possibilities=improved_predictions, prediction_error=prediction_error, initial_expectation_id=expectation_id)\n",
    "    expectation_revision_id = create_model(collection_name=\"expectation_revisions\", model_data=new_expectation_revision, client=db_client)\n",
    "    \n",
    "    expectation_revision_dict = get_model(collection_name=\"expectation_revisions\", model_id=expectation_revision_id, client=db_client)\n",
    "    \n",
    "    chat_output.append_stdout(f\"USER PREDICTION TASK COMPLETED\\nexpectation_revision_dict ID: {expectation_revision_dict['_id']}\", debug=True)\n",
    "    \n",
    "    return expectation_revision_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input_task() -> dict:\n",
    "    chat_output.append_stdout(f\"USER INPUT TASK\", debug=True)\n",
    "    chat_output.append_stdout(f\"user_input_queue: {user_input_queue.__dict__}\", debug=True)\n",
    "    \n",
    "    try:\n",
    "        user_input = user_input_queue.get()\n",
    "        \n",
    "        print_user_message(user_input)\n",
    "        \n",
    "        new_chat_message = create_chat_message(user_id=set_user['_id'], content=user_input, conversation_id=set_conversation['_id'])\n",
    "        chat_message_id = create_model(collection_name=\"chat_messages\", model_data=new_chat_message, client=db_client)\n",
    "        chat_message_dict = get_model(collection_name=\"chat_messages\", model_id=chat_message_id, client=db_client)\n",
    "        \n",
    "        chat_output.append_stdout(f\"USER INPUT TASK COMPLETED\\nchat message dict: {chat_message_dict}\", debug=True)\n",
    "        \n",
    "        return chat_message_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voe_task(expectation_id: ObjectId) -> dict:\n",
    "    try:\n",
    "        # invoke violation of expectation with LLM service\n",
    "        voe_thought = mock_violation_data['voe_thought']\n",
    "        \n",
    "        # implement DB call\n",
    "        last_llm_response = None\n",
    "        \n",
    "        new_violation = create_violation(last_llm_response_id=last_llm_response, expectation_id=expectation_id, voe_thought=voe_thought)\n",
    "        violation_id = create_model(collection_name=\"violations\", model_data=new_violation, client=db_client)\n",
    "        violation_dict = get_model(collection_name=\"violations\", model_id=violation_id, client=db_client)\n",
    "        \n",
    "        return violation_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response_task(response_to_id: ObjectId):\n",
    "    try:\n",
    "        user_message_dict = get_model(collection_name=\"chat_messages\", model_id=response_to_id, client=db_client)\n",
    "        chat_output.append_stdout(f\"{user_message_dict}\", debug=True)\n",
    "        user_message_model: ChatMessageData = user_message_dict[\"model\"]\n",
    "        chat_output.append_stdout(f\"user_message_model: {user_message_model}\",debug=True)\n",
    "        \n",
    "        # invoke prompt creation with useful information\n",
    "        \n",
    "        # invoke chatbot response with LLM Service\n",
    "        generated_response = chatbot(user_message_model.content)\n",
    "        chat_output.append_stdout(f\"generated_response: {generated_response}\", debug=True)\n",
    "        \n",
    "        # save final API output as \"content\"\n",
    "        content = generated_response\n",
    "        \n",
    "        new_chatbot_response = create_chatbot_response(content=content, conversation_id=set_conversation['_id'], response_to_id=response_to_id)\n",
    "        response_id = create_model(collection_name=\"chatbot_responses\", model_data=new_chatbot_response, client=db_client)\n",
    "        response_dict = get_model(collection_name=\"chatbot_responses\", model_id=response_id, client=db_client)\n",
    "        \n",
    "        return response_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_loop():\n",
    "    global text_input\n",
    "    active = True\n",
    "    text_input = widgets.Text(placeholder='Type your message here...')\n",
    "    submit_button = widgets.Button(description='Submit')\n",
    "    exit_button = widgets.Button(description='Exit')\n",
    "\n",
    "    def on_submit_button_clicked(b):\n",
    "        with chat_output:\n",
    "            # invoke user input task and return user message\n",
    "            handle_button_click()\n",
    "            if active:\n",
    "                message_dict = user_input_task()\n",
    "                chat_output.append_stdout(f\"Received message_dict: {message_dict}\", debug=True)                \n",
    "                message_id = message_dict[\"_id\"]\n",
    "    \n",
    "                # invoke user prediction task and return prediction object\n",
    "                expectation_dict = user_prediction_task()\n",
    "                chat_output.append_stdout(f\"Received prediction: {expectation_dict}\", debug=True)\n",
    "                expectation_id = expectation_dict[\"_id\"]\n",
    "    \n",
    "                # invoke violation of expectation task and return violation object\n",
    "                violation_dict = voe_task(expectation_id=expectation_id)\n",
    "                chat_output.append_stdout(f\"Received violation: {violation_dict}\", debug=True)\n",
    "                \n",
    "                # invoke vector db fact storing with Knowledge Assessment Service\n",
    "                \n",
    "                # invoke chatbot response task and return chatbot message\n",
    "                chatbot_response_dict = chatbot_response_task(message_id)\n",
    "                chat_output.append_stdout(f\"Received response: {chatbot_response_dict}\", debug=True)\n",
    "\n",
    "    submit_button.on_click(on_submit_button_clicked)\n",
    "\n",
    "    def on_exit_button_clicked(b):\n",
    "        nonlocal active\n",
    "        with chat_output:\n",
    "            active = False\n",
    "            chat_output.clear_output()\n",
    "            chat_output.append_stdout(\"Exiting conversation loop...\")\n",
    "\n",
    "    exit_button.on_click(on_exit_button_clicked)\n",
    "\n",
    "    display(widgets.VBox([chat_output, text_input, submit_button, exit_button]))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    initialize_chat(saved_user_id, ObjectId('65f1c96cc63f2e5bb56d6976'))\n",
    "    chat_output.append_stdout(f\"user: {set_user}\\nconversation: {set_conversation}\")\n",
    "    print_chat_history()\n",
    "    conversation_loop()\n",
    "\n",
    "if __name__ == \"__main__\": main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
