{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# metacognitive prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import sys\n",
    "import queue\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getenv(\"SYS_PATH\"))\n",
    "print(f'{os.getenv(\"SYS_PATH\")}\\n\\n')\n",
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from ipywidgets import widgets\n",
    "from IPython.display import display, clear_output\n",
    "from bson.objectid import ObjectId\n",
    "from typing import Optional\n",
    "import threading\n",
    "\n",
    "from models.user import create_user\n",
    "from models.chat_message import create_chat_message\n",
    "from models.conversation import create_conversation\n",
    "from models.chatbot_response import create_chatbot_response\n",
    "from models.expectation import create_expectation\n",
    "from models.expectation_revision import create_expectation_revision\n",
    "from models.violation import create_violation\n",
    "\n",
    "from utils.model_operations import create_model, get_model\n",
    "from services.mock_service import mock_user_data, mock_expectation_data, mock_expectation_revision_data, mock_message_data, mock_violation_data, mock_chatbot_response_data\n",
    "from utils.helpers import CustomOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../services/mongo_service.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.mongo_service import mongo_client, ping_client\n",
    "db_client = mongo_client()\n",
    "ping_client(db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = \"\"\n",
    "chat_output = CustomOutput()\n",
    "\n",
    "user_input_queue = queue.Queue()\n",
    "set_user = None\n",
    "set_conversation = None\n",
    "active = True\n",
    "\n",
    "processing_message = threading.Event()\n",
    "button_click_event = threading.Event()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_user = create_user(email=mock_user_data[\"email\"], password=mock_user_data[\"password\"])\n",
    "print(f\"test_user: {test_user}\\nis of type{type(test_user)}\")\n",
    "saved_user_id = create_model(collection_name=\"users\", model_data=test_user, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_conversation = create_conversation(user_id=saved_user_id)\n",
    "saved_conversation_id = create_model(collection_name=\"conversations\", model_data=test_conversation, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_expectation = create_expectation(reasoning=mock_expectation_data[\"reasoning\"], user_predictions=mock_expectation_data[\"user_predictions\"], additional_data=mock_expectation_data[\"additional_data\"])\n",
    "saved_expectation_id = create_model(collection_name=\"expectations\", model_data=test_expectation, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_expectation_revision = create_expectation_revision(revised_input_possibilities=mock_expectation_revision_data[\"revised_input_possibilities\"], prediction_error=-0.045, initial_expectation_id=saved_expectation_id)\n",
    "saved_expectation_revision_id = create_model(collection_name=\"expectation_revisions\", model_data=test_expectation_revision, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_message = create_chat_message(user_id=saved_user_id, content=mock_message_data[\"content\"], conversation_id=saved_conversation_id)\n",
    "saved_message_id = create_model(collection_name=\"chat_messages\", model_data=test_message, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_violation = create_violation(last_llm_response_id=None, expectation_id=saved_expectation_id, voe_thought=mock_violation_data[\"voe_thought\"])\n",
    "saved_violation_id = create_model(collection_name=\"violations\", model_data=test_violation, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_model(collection_name=\"users\", model_id=saved_user_id, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mock_expectation_data[\"reasoning\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai_client = OpenAI(\n",
    "    api_key=apikey\n",
    ")\n",
    "print(openai_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    ":::{admonition} `stream_chatbot` docs\n",
    ":class: dropdown \n",
    "\n",
    "### `stream_chatbot(message)`\n",
    "\n",
    "This function interacts with the chatbot using stream functionality.\n",
    "\n",
    "**Parameters:**\n",
    "- `message`: The message sent by the user to the chatbot.\n",
    "\n",
    "**Returns:**\n",
    "- None\n",
    "\n",
    "**Functionality:**\n",
    "- Sends the user message to the chatbot.\n",
    "- Receives and prints the response from the chatbot.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_chatbot(message):\n",
    "    chat_completion_stream = openai_client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\":message,\n",
    "             },\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        stream=True\n",
    "    )\n",
    "    print(chat_completion_stream)\n",
    "    for chunk in chat_completion_stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            chat_output.append_stdout(f\"{chunk.choices[0].delta.content}\")\n",
    "    chat_output.append_stdout(f\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    ":::{admonition} `chatbot` docs\n",
    ":class: dropdown\n",
    "\n",
    "### `chatbot(user_message)`\n",
    "\n",
    "This function interacts with the chatbot based on user input.\n",
    "\n",
    "**Parameters:**\n",
    "- `user_message`: The message provided by the user.\n",
    "\n",
    "**Returns:**\n",
    "- None\n",
    "\n",
    "**Functionality:**\n",
    "- Initiates interaction with the chatbot by passing the user's message.\n",
    "- Prints the chatbots response.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(user_message):\n",
    "    global active\n",
    "    processing_message.set()\n",
    "    chat_output.append_stdout(\"Chatbot: \")\n",
    "    if user_message.lower() in [\"bye!\", \"quit\", \"exit\"]:\n",
    "        chat_output.append_stdout(\"BYE\\n\\n\")\n",
    "        active = False\n",
    "    else:\n",
    "        stream_chatbot(user_message)\n",
    "    processing_message.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    ":::{admonition} `print_user_message` docs\n",
    ":class: dropdown\n",
    "\n",
    "### `print_user_message(user_message)`\n",
    "\n",
    "This function prints the user's message.\n",
    "\n",
    "**Parameters:**\n",
    "- `user_message`: The message provided by the user.\n",
    "\n",
    "**Returns:**\n",
    "- None\n",
    "\n",
    "**Functionality:**\n",
    "- Prints the user's message in the format: \"You: [user_message]\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_user_message(user_message):\n",
    "    chat_output.append_stdout(f\"You: {user_message}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_user_message(user_message):\n",
    "    chatbot(user_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_button_click():\n",
    "    chat_output.append_stdout(f\"handle button clicked\\n\\n\", debug=True)\n",
    "    chat_output.append_stdout(f\"button_click_event.is_set(): {button_click_event.is_set()}\\n\\n\", debug=True)\n",
    "    chat_output.append_stdout(f\"handle button clicked before wait\\n\\n\", debug=True)\n",
    "    chat_output.append_stdout(f\"handle button clicked after wait\\n\\n\", debug=True)\n",
    "    chat_output.append_stdout(f\"std statement, processing msg: {processing_message.is_set()}\\n\\n\", debug=True)\n",
    "    if not processing_message.is_set():\n",
    "        chat_output.append_stdout(f\"BUTTON CLICK FN TRIGGERED\\nprocessing message set status: {processing_message.is_set()}\\n\\n\", debug=True)\n",
    "        chat_output.append_stdout(f\"text_input.value: {text_input.value}\\n\\n\", debug=True)\n",
    "        user_input_queue.put(text_input.value)\n",
    "        text_input.value=''\n",
    "    chat_output.append_stdout(f\"handle button clicked after clearing button event and setting queue event\\n\\n\", debug=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chat(user_id: ObjectId, conversation_id: Optional[ObjectId] = None):\n",
    "    global set_user, set_conversation\n",
    "    set_user = get_model(collection_name=\"users\", model_id=saved_user_id, client=db_client)\n",
    "    if not conversation_id:\n",
    "        new_conversation = create_conversation(user_id=user_id)\n",
    "        conversation_id = create_model(collection_name=\"conversations\", model_data=new_conversation, client=db_client)\n",
    "    set_conversation = get_model(collection_name=\"conversations\", model_id=conversation_id, client=db_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prediction_task() -> dict:\n",
    "    # invoke reasoning process with Engagement Monitor Service\n",
    "    reasoning = mock_expectation_data[\"reasoning\"]\n",
    "    \n",
    "    # invoke user predictions with LLM Service\n",
    "    user_predictions = mock_expectation_data[\"user_predictions\"]\n",
    "    \n",
    "    # invoke vector db fact fetching with Knowledge Assessment Service\n",
    "    additional_data = mock_expectation_data[\"additional_data\"]\n",
    "    \n",
    "    # create and save Expectation\n",
    "    new_expectation = create_expectation(reasoning=reasoning, user_predictions=user_predictions, additional_data=additional_data)\n",
    "    expectation_id = create_model(collection_name=\"expectations\", model_data=new_expectation, client=db_client)\n",
    "    \n",
    "    # invoke prediction improvement with LLM Service\n",
    "    improved_predictions = mock_expectation_revision_data[\"revised_input_possibilities\"]\n",
    "    \n",
    "    # invoke prediction error calculation with ??? Service\n",
    "    prediction_error = 0.0\n",
    "    \n",
    "    # create and save ExpectationRevision\n",
    "    new_expectation_revision = create_expectation_revision(revised_input_possibilities=improved_predictions, prediction_error=prediction_error, initial_expectation_id=expectation_id)\n",
    "    expectation_revision_id = create_model(collection_name=\"expectation_revisions\", model_data=new_expectation_revision, client=db_client)\n",
    "    \n",
    "    expectation_revision_dict = get_model(collection_name=\"expectation_revisions\", model_id=expectation_revision_id, client=db_client)\n",
    "    \n",
    "    chat_output.append_stdout(f\"USER PREDICTION TASK COMPLETED\\nexpectation_revision_dict ID: {expectation_revision_dict['_id']}\\n\\n\", debug=True)\n",
    "    \n",
    "    return expectation_revision_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input_task() -> dict:\n",
    "    chat_output.append_stdout(f\"USER INPUT TASK\\n\\n\", debug=True)\n",
    "    chat_output.append_stdout(f\"user_input_queue: {user_input_queue.__dict__}\\n\\n\", debug=True)\n",
    "    \n",
    "    try:\n",
    "        user_input = user_input_queue.get()\n",
    "        \n",
    "        chat_output.append_stdout(f\"USER INPUT: {user_input}\\n\\n\")\n",
    "        \n",
    "        new_chat_message = create_chat_message(user_id=set_user['_id'], content=user_input, conversation_id=set_conversation['_id'])\n",
    "        chat_message_id = create_model(collection_name=\"chat_messages\", model_data=new_chat_message, client=db_client)\n",
    "        chat_message_dict = get_model(collection_name=\"chat_messages\", model_id=chat_message_id, client=db_client)\n",
    "        \n",
    "        chat_output.append_stdout(f\"USER INPUT TASK COMPLETED\\nchat message dict: {chat_message_dict}\\n\\n\", debug=True)\n",
    "        \n",
    "        return chat_message_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Handle the case when the queue is empty\n",
    "        chat_output.append_stdout(f\"EXCEPTION: {e}\\n\\n\", debug=True)\n",
    "        \n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def voe_task(expectation_id: ObjectId) -> dict:\n",
    "    try:\n",
    "        # invoke violation of expectation with LLM service\n",
    "        voe_thought = mock_violation_data['voe_thought']\n",
    "        \n",
    "        # implement DB call\n",
    "        last_llm_response = None\n",
    "        \n",
    "        new_violation = create_violation(last_llm_response_id=last_llm_response, expectation_id=expectation_id, voe_thought=voe_thought)\n",
    "        violation_id = create_model(collection_name=\"violations\", model_data=new_violation, client=db_client)\n",
    "        violation_dict = get_model(collection_name=\"violations\", model_id=violation_id, client=db_client)\n",
    "        \n",
    "        return violation_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        chat_output.append_stdout(f\"EXCEPTION: {e}\\n\\n\", debug=True)\n",
    "        \n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_response_task(response_to_id: ObjectId):\n",
    "    try:\n",
    "        response_to_message = get_model(collection_name=\"chat_messages\", model_id=response_to_id, client=db_client)\n",
    "        \n",
    "        # invoke prompt creation with useful information\n",
    "        \n",
    "        # invoke chatbot response with LLM Service\n",
    "        \n",
    "        # save final API output as \"content\"\n",
    "        content = mock_chatbot_response_data[\"content\"]\n",
    "        \n",
    "        new_chatbot_response = create_chatbot_response(content=content, conversation_id=set_conversation['_id'], response_to_id=response_to_id)\n",
    "        response_id = create_model(collection_name=\"chatbot_responses\", model_data=new_chatbot_response, client=db_client)\n",
    "        response_dict = get_model(collection_name=\"chatbot_responses\", model_id=response_id, client=db_client)\n",
    "        \n",
    "        return response_dict\n",
    "    \n",
    "    except Exception as e:\n",
    "        chat_output.append_stdout(f\"EXCEPTION: {e}\\n\\n\", debug=True)\n",
    "\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation_loop():\n",
    "    global text_input\n",
    "    text_input = widgets.Text(placeholder='Type your message here...')\n",
    "    submit_button = widgets.Button(description='Submit')\n",
    "    exit_button = widgets.Button(description='Exit')\n",
    "\n",
    "    def on_submit_button_clicked(b):\n",
    "        with chat_output:\n",
    "            # invoke user input task and return user message\n",
    "            handle_button_click()\n",
    "            message_dict = user_input_task()\n",
    "            chat_output.append_stdout(f\"Received message_dict: {message_dict}\\n\\n\", debug=True)                \n",
    "            message_id = message_dict[\"_id\"]\n",
    "\n",
    "            # invoke user prediction task and return prediction object\n",
    "            expectation_dict = user_prediction_task()\n",
    "            chat_output.append_stdout(f\"Received prediction: {expectation_dict}\\n\\n\", debug=True)\n",
    "            expectation_id = expectation_dict[\"_id\"]\n",
    "\n",
    "            # invoke violation of expectation task and return violation object\n",
    "            violation_dict = voe_task(expectation_id=expectation_id)\n",
    "            chat_output.append_stdout(f\"Received violation: {violation_dict}\", debug=True)\n",
    "            \n",
    "            # invoke vector db fact storing with Knowledge Assessment Service\n",
    "            \n",
    "            # invoke chatbot response task and return chatbot message\n",
    "            chatbot_response_dict = chatbot_response_task(message_id)\n",
    "            chat_output.append_stdout(f\"Received response: {chatbot_response_dict}\", debug=True)\n",
    "\n",
    "    submit_button.on_click(on_submit_button_clicked)\n",
    "\n",
    "    def on_exit_button_clicked(b):\n",
    "        with chat_output:\n",
    "            chat_output.clear_output()\n",
    "            chat_output.append_stdout(\"Exiting conversation loop...\")\n",
    "\n",
    "    exit_button.on_click(on_exit_button_clicked)\n",
    "\n",
    "    display(widgets.VBox([chat_output, text_input, submit_button, exit_button]))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    initialize_chat(saved_user_id)\n",
    "    chat_output.append_stdout(f\"user: {set_user}\\nconversation: {set_conversation}\\n\\n\")\n",
    "    conversation_loop()\n",
    "\n",
    "if __name__ == \"__main__\": main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
